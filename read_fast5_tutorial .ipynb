{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Oxford Nanopore sequencing data into Python.\n",
    "Data from nanopore sequencing are stored in a fast5 (HDF) file, which essentially is a container of various object types.  \n",
    "Before we do any kind of analysis on this data we will need to do some \"Data Wrangling\" to get it into python, and into the format we want.  \n",
    "We will first import all of the python modules we are going to need. Of particular note here is **h5py**. The best way to install this is to open a terminal window and type the following (without the $):  \n",
    ">`$ conda install h5py`  \n",
    "\n",
    "You may need to close this notebook, and any terminal windows, and reopen jupyter notebook for the import to work.  \n",
    "If you are on a Windows machine, or you dont have Anaconda, go to http://docs.h5py.org/en/latest/build.html for instructions on how to install this module on your machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import h5py as h5, numpy as np, os, sys, urllib, lxml.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, we are going to load some example fast5 files into python with some web scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path = \"http://data.genomicsresearch.org/internal/Nanopore/Ecoli/porecamp/\"\n",
    "connection = urllib.urlopen(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next block will get the URL links for all of the example fast5 files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dom = lxml.html.fromstring(connection.read())\n",
    "f5_files = []\n",
    "for link in dom.xpath('//a/@href')[5:]: # first 5 links are not files on this page\n",
    "    f5_files.append(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5CG6210Y8Z_20160816_FNFAB28012_MN15120_mux_scan_GroupB_1D_Ecoli_2016_53944_ch111_read44_strand.fast5\n",
      "5CG6210Y8Z_20160816_FNFAB28012_MN15120_sequencing_run_GroupB_1D_Ecoli_2016_67932_ch100_read1054_strand.fast5\n",
      "5CG6210Y8Z_20160816_FNFAB28012_MN15120_sequencing_run_GroupB_1D_Ecoli_2016_67932_ch100_read1103_strand.fast5\n",
      "5CG6210Y8Z_20160816_FNFAB28012_MN15120_sequencing_run_GroupB_1D_Ecoli_2016_67932_ch100_read1111_strand.fast5\n",
      "5CG6210Y8Z_20160816_FNFAB28012_MN15120_sequencing_run_GroupB_1D_Ecoli_2016_67932_ch100_read1451_strand.fast5\n",
      "5CG6210Y8Z_20160816_FNFAB28012_MN15120_sequencing_run_GroupB_1D_Ecoli_2016_67932_ch100_read1731_strand.fast5\n"
     ]
    }
   ],
   "source": [
    "# here is the file names for the fast5 files we are going to look at\n",
    "for filename in f5_files:\n",
    "    print filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# turn these filenames into their respective URLs\n",
    "f5_urls = [path + f for f in f5_files]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This line will copy these fast5 files into your current directory on your local machine so we can start using them (the files are not very big ~1-2MB)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i, f in enumerate(f5_urls):\n",
    "    opener = urllib.URLopener()\n",
    "    opener.retrieve(f, f5_files[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get FAST5 files into python and start wrangling\n",
    "Now we are going to do the extremely import steps of getting our FAST5 files read for our training.  \n",
    "\n",
    "Lets define a function that, given a filename, will load the FAST5 file in and extract the bits we are interested in for our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_and_extract_fast5(filename):\n",
    "    \"\"\"Function reads in a FAST5 file and returns the detected events, \n",
    "    the base-called events and the FASTQ file.\n",
    "    \n",
    "    load_and_extract_fast5(string) -> np.array, np.string_, np.array\n",
    "    \n",
    "    Preconditions: Must have h5py and numpy modules installed. Also,\n",
    "    this function will only extract 1D information.\n",
    "    \"\"\"\n",
    "    import h5py as h5, numpy as np, os, sys\n",
    "    # a list to sotre the names of the \"groups\" - similar to keys in a dictionary\n",
    "    lst_names = []\n",
    "    # open the fast5 file - closes automatically when loop is finished.\n",
    "    with h5.File(filename, 'r') as f:\n",
    "        # gets the name of all of the groups and stores them in our list\n",
    "        f.visit(lst_names.append)\n",
    "        \n",
    "        # get the names of the groups we are interested in\n",
    "        groups = []\n",
    "        for name in lst_names:\n",
    "            if name.endswith(\"Events\") or name.endswith(\"template/Fastq\"):\n",
    "                if not name.endswith(\"complement/Events\") and \"2D\" not in name:\n",
    "                    groups.append(name)\n",
    "        \n",
    "        # catch if there are more than 3 elements in the groups that have been extracted\n",
    "        if len(groups) != 3:\n",
    "            raise IndexError(\"{0} groups detected. Need 3 groups. Speak to Michael if you see this.\".format(len(groups)))\n",
    "\n",
    "        \n",
    "        # extract the information from the basecalled events\n",
    "        events = f[groups[0]].value\n",
    "        called_events = np.array([x for xs in events for x in xs]).reshape(len(events), \n",
    "                                                                           len(events[0]))\n",
    "        \n",
    "        # extract the FASTQ file\n",
    "        fastq = f[groups[1]].value\n",
    "        \n",
    "        # extract the information from the detected events - before basecalling\n",
    "        dataset = f[groups[2]].value\n",
    "        event_detection = np.array([x for xs in dataset for x in xs]).reshape(len(dataset), \n",
    "                                                                              len(dataset[0]))\n",
    "         \n",
    "        return called_events, fastq, event_detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a function that can extract the information we want, lets go ahead and implement this function on our FAST5 files.  \n",
    "For the purpose of this example we will store them in a dictionary whose key will be the read id. For future though you may want to use/name/store the data differently. i.e here we set the keys to be the read id, but read ID may not necessarily be a unique identifier in other circumstances. Always check this first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f5_data = {}\n",
    "for f5 in f5_files:\n",
    "    f5_data[f5.split(\"_\")[-2]] = load_and_extract_fast5(f5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These event files do not have column names. For the sake of understanding we will also generate two lists that correspond to column names for the 2 events arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "called_events_colnames = [\"mean\", \"start\", \"stdv\", \"length\", \"model_state\", \n",
    "                          \"move\", \"weights\", \"p_model_state\", \"mp_state\", \n",
    "                          \"p_mp_state\", \"p_A\", \"p_C\", \"p_G\", \"p_T\"]\n",
    "event_detection_colnames = [\"start\", \"length\", \"mean\", \"stdv\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Closing Remarks\n",
    "Bare in mind that the purpose of this notebook was to help you get your head around loading and manipulating data - specifically FAST5 files - in python. Whilst it is intended that some of the above code will help with curating our dataset for the training of our neural network, science does not always play nice and we have to troubleshoot and problem solve to find ways around these obstacles.  \n",
    "What I mean by this is that **when running this notebook make sure you play around with the code and add in lots of print statements to see what is happening under the hood** - especially in lines that you do not understand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
